{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e40b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "WEEK 5 - DAY 2-3: GPU Training Large Models\n",
      "======================================================================\n",
      "\n",
      "Using device: cuda\n",
      "GPU: Tesla T4\n",
      "Memory: 15.83 GB\n",
      "\n",
      ">>> Setting up Advanced Data Augmentation\n",
      " Transforms configured\n",
      "   Training: Crop, Flip, Rotation, ColorJitter, Cutout\n",
      "   Test: Normalize only\n",
      "\n",
      ">>> Loading CIFAR-10\n",
      "Training: 45000\n",
      "Validation: 5000\n",
      "Test: 10000\n",
      "\n",
      ">>> Building ResNet50 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 219MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ResNet50 created\n",
      "   Total parameters: 23,520,842\n",
      "   Trainable parameters: 23,520,842\n",
      "\n",
      ">>> Setting up Training\n",
      "âœ… Training setup complete\n",
      "   Loss: CrossEntropyLoss\n",
      "   Optimizer: AdamW (lr=0.001, weight_decay=0.01)\n",
      "   Scheduler: OneCycleLR (max_lr=0.01, 30 epochs)\n",
      "\n",
      ">>> Training ResNet50\n",
      "\n",
      "Epoch | Train Loss | Train Acc | Val Loss | Val Acc | LR      | Time\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory /content/drive/MyDrive/ai_engineering does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2380136472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         torch.save({\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             _save(\n\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             super().__init__(\n\u001b[0;32m--> 792\u001b[0;31m                 torch._C.PyTorchFileWriter(\n\u001b[0m\u001b[1;32m    793\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_crc32_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_storage_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /content/drive/MyDrive/ai_engineering does not exist."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WEEK 5 - DAY 2-3: Training Large Models with GPU\n",
    "================================================\n",
    "Train ResNet50 and EfficientNet on CIFAR-10 to achieve 90%+ accuracy\n",
    "\n",
    "IMPORTANT: Run this in Google Colab with GPU enabled!\n",
    "\n",
    "Topics:\n",
    "- Training larger models (ResNet50, EfficientNet)\n",
    "- Advanced data augmentation\n",
    "- Learning rate scheduling\n",
    "- Mixed precision training\n",
    "- Saving checkpoints\n",
    "- Achieving 90%+ accuracy\n",
    "\"\"\"\n",
    "\n",
    "# ============================================\n",
    "# SETUP\n",
    "# ============================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"WEEK 5 - DAY 2-3: GPU Training Large Models\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check environment\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# ============================================\n",
    "# ADVANCED DATA AUGMENTATION\n",
    "# ============================================\n",
    "print(\"\\n>>> Setting up Advanced Data Augmentation\")\n",
    "\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# Training transforms (aggressive augmentation for CIFAR-10)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33)),  # Cutout\n",
    "])\n",
    "\n",
    "# Test transforms (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\" Transforms configured\")\n",
    "print(\"   Training: Crop, Flip, Rotation, ColorJitter, Cutout\")\n",
    "print(\"   Test: Normalize only\")\n",
    "\n",
    "# ============================================\n",
    "# LOAD DATASETS\n",
    "# ============================================\n",
    "print(\"\\n>>> Loading CIFAR-10\")\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root='/content/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='/content/data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Create validation split\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(train_dataset)}\")\n",
    "print(f\"Validation: {len(val_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ============================================\n",
    "# BUILD MODEL: ResNet50\n",
    "# ============================================\n",
    "print(\"\\n>>> Building ResNet50 Model\")\n",
    "\n",
    "def build_resnet50(num_classes=10, pretrained=True):\n",
    "    \"\"\"Build ResNet50 for CIFAR-10\"\"\"\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    \n",
    "    # Modify first conv for 32x32 images\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()  # Remove maxpool\n",
    "    \n",
    "    # Replace final layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_resnet50(num_classes=10, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"âœ… ResNet50 created\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# ============================================\n",
    "# TRAINING SETUP\n",
    "# ============================================\n",
    "print(\"\\n>>> Setting up Training\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.01,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=30,\n",
    "    pct_start=0.3\n",
    ")\n",
    "\n",
    "print(\"âœ… Training setup complete\")\n",
    "print(f\"   Loss: CrossEntropyLoss\")\n",
    "print(f\"   Optimizer: AdamW (lr=0.001, weight_decay=0.01)\")\n",
    "print(f\"   Scheduler: OneCycleLR (max_lr=0.01, 30 epochs)\")\n",
    "\n",
    "# ============================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scheduler, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    for inputs, targets in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.3f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# ============================================\n",
    "# TRAINING LOOP\n",
    "# ============================================\n",
    "print(\"\\n>>> Training ResNet50\")\n",
    "\n",
    "num_epochs = 30\n",
    "best_val_acc = 0.0\n",
    "train_losses, train_accs = [], []\n",
    "val_losses, val_accs = [], []\n",
    "\n",
    "print(\"\\nEpoch | Train Loss | Train Acc | Val Loss | Val Acc | LR      | Time\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Get current LR\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, '/content/drive/MyDrive/ai_engineering/best_resnet50.pth')\n",
    "    \n",
    "    # Save checkpoint every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, f'/content/drive/MyDrive/ai_engineering/checkpoint_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"{epoch+1:5d} | {train_loss:10.4f} | {train_acc:9.2f}% | \"\n",
    "          f\"{val_loss:8.4f} | {val_acc:7.2f}% | {current_lr:.6f} | {elapsed:.1f}s\")\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "# ============================================\n",
    "# EVALUATE ON TEST SET\n",
    "# ============================================\n",
    "print(\"\\n>>> Evaluating on Test Set\")\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('/content/drive/MyDrive/ai_engineering/best_resnet50.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Per-class accuracy\n",
    "class_correct = [0] * 10\n",
    "class_total = [0] * 10\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        c = predicted.eq(targets)\n",
    "        \n",
    "        for i in range(len(targets)):\n",
    "            label = targets[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for i in range(10):\n",
    "    acc = 100 * class_correct[i] / class_total[i]\n",
    "    print(f\"{classes[i]:10s}: {acc:5.2f}%\")\n",
    "\n",
    "# ============================================\n",
    "# VISUALIZATION\n",
    "# ============================================\n",
    "print(\"\\n>>> Creating Visualizations\")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(train_losses, label='Train Loss', linewidth=2)\n",
    "axes[0].plot(val_losses, label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(train_accs, label='Train Acc', linewidth=2)\n",
    "axes[1].plot(val_accs, label='Val Acc', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/ai_engineering/resnet50_training.png', dpi=150, bbox_inches='tight')\n",
    "print(\"âœ… Training curves saved\")\n",
    "\n",
    "# Visualize predictions\n",
    "model.eval()\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = outputs.max(1)\n",
    "    \n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < len(images):\n",
    "            # Denormalize\n",
    "            img = images[idx].cpu()\n",
    "            img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            img = img + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            ax.imshow(img)\n",
    "            color = 'green' if predicted[idx] == labels[idx] else 'red'\n",
    "            ax.set_title(f'True: {classes[labels[idx]]}\\nPred: {classes[predicted[idx]]}',\n",
    "                        color=color, fontsize=9)\n",
    "            ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/drive/MyDrive/ai_engineering/resnet50_predictions.png', dpi=150, bbox_inches='tight')\n",
    "print(\"âœ… Predictions saved\")\n",
    "\n",
    "# ============================================\n",
    "# BONUS: EfficientNet-B0\n",
    "# ============================================\n",
    "print(\"\\n>>> BONUS: Training EfficientNet-B0\")\n",
    "\n",
    "def build_efficientnet(num_classes=10, pretrained=True):\n",
    "    \"\"\"Build EfficientNet-B0\"\"\"\n",
    "    model = models.efficientnet_b0(pretrained=pretrained)\n",
    "    \n",
    "    # Replace classifier\n",
    "    num_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train EfficientNet (optional - takes more time)\n",
    "print(\"Building EfficientNet-B0...\")\n",
    "efficientnet = build_efficientnet(num_classes=10, pretrained=True)\n",
    "efficientnet = efficientnet.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in efficientnet.parameters())\n",
    "print(f\"âœ… EfficientNet-B0 created\")\n",
    "print(f\"   Parameters: {total_params:,}\")\n",
    "print(\"\\nðŸ’¡ To train EfficientNet, use the same training loop above\")\n",
    "print(\"   Expected accuracy: 90-92%\")\n",
    "\n",
    "# ============================================\n",
    "# GPU MEMORY STATS\n",
    "# ============================================\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n>>> GPU Memory Usage\")\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "    print(f\"Reserved: {torch.cuda.memory_reserved()/1e9:.2f} GB\")\n",
    "    print(f\"Max allocated: {torch.cuda.max_memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "# ============================================\n",
    "# KEY TAKEAWAYS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY TAKEAWAYS - Day 2-3\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. LARGE MODEL TRAINING:\n",
    "   âœ… ResNet50: 25M parameters\n",
    "   âœ… EfficientNet-B0: 5M parameters\n",
    "   âœ… GPU makes training feasible (~10 min/epoch)\n",
    "   âœ… Expected accuracy: 90-92%\n",
    "\n",
    "2. ADVANCED AUGMENTATION:\n",
    "   - RandomCrop with padding\n",
    "   - RandomHorizontalFlip\n",
    "   - ColorJitter\n",
    "   - RandomErasing (Cutout)\n",
    "   â†’ Improves generalization by 3-5%\n",
    "\n",
    "3. LEARNING RATE SCHEDULING:\n",
    "   - OneCycleLR: Best for short training\n",
    "   - Starts low, peaks mid-training, ends low\n",
    "   - Faster convergence than fixed LR\n",
    "\n",
    "4. CHECKPOINTING:\n",
    "   - Save best model (highest val acc)\n",
    "   - Save periodic checkpoints\n",
    "   - Resume training if interrupted\n",
    "\n",
    "5. GPU OPTIMIZATION:\n",
    "   - Use pin_memory=True in DataLoader\n",
    "   - Use num_workers=2 for data loading\n",
    "   - Monitor GPU memory\n",
    "   - Clear cache if needed: torch.cuda.empty_cache()\n",
    "\n",
    "6. RESULTS:\n",
    "   - Baseline (CPU, Week 3): 65-75%\n",
    "   - With transfer learning (Week 4): 82%\n",
    "   - With GPU + larger model: 90-92% âœ¨\n",
    "\n",
    "TRAINING TIME COMPARISON:\n",
    "- CPU (ResNet18): ~5 min/epoch\n",
    "- GPU (ResNet18): ~30 sec/epoch (10x faster)\n",
    "- GPU (ResNet50): ~1.5 min/epoch\n",
    "- GPU (EfficientNet): ~2 min/epoch\n",
    "\n",
    "NEXT: Model optimization and deployment!\n",
    "\"\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ… Day 2-3 Complete!\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  - best_resnet50.pth (model weights)\")\n",
    "print(\"  - resnet50_training.png (training curves)\")\n",
    "print(\"  - resnet50_predictions.png (sample predictions)\")\n",
    "print(\"\\nAll files saved to Google Drive!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
